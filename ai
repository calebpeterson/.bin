#!/usr/bin/env zx

import OpenAI from "openai";
import { ENV } from "./lib/read-env.mjs";

const EXIT_TOKEN = ".exit";
const USER_PROMPT = chalk.white("▸ ");
const ASSISTANT_FORMAT = chalk.blue;
const ASSISTANT_PROMPT = ASSISTANT_FORMAT("▸ ");

const openai = new OpenAI({
  organization: ENV.OPENAI_ORGANIZATION,
  apiKey: ENV.OPENAI_API_KEY,
});

if (argv.models) {
  const response = await openai.models.list();
  const models = response.data;
  const chatModels = models.filter(
    (model) =>
      // All GPT models
      model.id.includes("gpt-") &&
      // Exclude fine-tuned models
      !model.id.includes("ft:")
  );

  console.log("Available Chat Models:");

  console.log();
  for (const model of chatModels) {
    console.log("  " + model.id);
  }
  console.log();

  process.exit(0);
}

const model = argv.model || "gpt-4o";

const messages = [];

// Stream the response to the console
async function streamResponse(userInput) {
  messages.push({ role: "user", content: userInput });

  const stream = await openai.chat.completions.create({
    model,
    messages,
    stream: true,
  });

  process.stdout.write(`\n${ASSISTANT_PROMPT}`);

  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || "";
    process.stdout.write(ASSISTANT_FORMAT(content));
  }

  process.stdout.write("\n\n" + USER_PROMPT);

  messages.push({
    role: "assistant",
    content: messages[messages.length - 1].content,
  });
}

// Main chat loop
console.log(`Chat started. Type '${EXIT_TOKEN}' to end the conversation.\n`);

while (true) {
  const input = await question(USER_PROMPT);

  if (input.toLowerCase() === EXIT_TOKEN) {
    process.exit(0);
  }

  await streamResponse(input);
}
