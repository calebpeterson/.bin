#!/usr/bin/env bun

/*
 * TODO:
 *
 * Inject selection + prompt into a new session
 */

import "zx/globals";
import OpenAI from "openai";
import { v4 as uuid4 } from "uuid";
import { ENV } from "./lib/read-env.mjs";
import { choose } from "./lib/index.mjs";
import { lines } from "./lib/lines";
import { formatMarkdown } from "./lib/format-markdown";
import { setTerminalTitle } from "./lib/set-terminal-title";
import { setStatusLine } from "./lib/set-status-line";
import { stringifyChat } from "./lib/stringify-llm-chat";
import { parseChat } from "./lib/parse-llm-chat";
import { ChatMessage, Conversation } from "./lib/llm-types";

console.clear();

const BASE_DIR = argv._[0] ?? os.homedir();
const ROOT_DIR = `${BASE_DIR}/.ai`;

let CONVERSATION_BASENAME = uuid4();

const EXIT_COMMAND = "/exit";
const NEW_COMMAND = "/new";
const RENAME_COMMAND = "/rename";
const DELETE_COMMAND = "/delete";
const COPY_COMMAND = "/copy";
const STATUS_COMMAND = "/status";

const USER_PROMPT = chalk.blue("â–¸ ");
const USER_PROMPT_2 = chalk.blue("  ");

const ASSISTANT_FORMAT = chalk.blue;
const ASSISTANT_PROMPT = ASSISTANT_FORMAT("");

const META_FORMAT = chalk.grey.italic;

// Ensure the conversations directory exists
await $`mkdir -p ${ROOT_DIR}`;

// Create the OpenAI client
const openai = new OpenAI({
  organization: ENV.OPENAI_ORGANIZATION,
  apiKey: ENV.OPENAI_API_KEY,
});

const getConversationBasenames = async () =>
  lines(await $`ls ${ROOT_DIR}`).map((filename) => path.parse(filename).name);

// List models and exit if given the --models flag
if (argv.models) {
  const response = await openai.models.list();
  const models = response.data;
  const chatModels = models.filter(
    (model) =>
      // All GPT models
      model.id.includes("gpt-") &&
      // Exclude fine-tuned models
      !model.id.includes("ft:")
  );

  console.log("Available Chat Models:");

  console.log();
  for (const model of chatModels) {
    console.log("  " + model.id);
  }
  console.log();

  process.exit(0);
}

// The LLM model to use
let model = argv.model ?? "gpt-4o";

// The messages in the conversation
const messages: Conversation = [];

// Prompt the user to pick from existing conversations
const chooseConversation = async () => {
  const conversationBasenames = await getConversationBasenames();
  const conversationBasename = await choose(conversationBasenames);

  return conversationBasename;
};

// Continue a previous conversation?
if (argv.continue || argv.resume) {
  const conversationBasename = await chooseConversation();

  if (!conversationBasename) {
    process.exit(1);
  }

  CONVERSATION_BASENAME = conversationBasename;

  const content = await fs.readFile(
    path.join(ROOT_DIR, conversationBasename + ".md"),
    "utf8"
  );
  const { meta, messages: history } = await parseChat(content);

  if ("model" in meta) {
    model = meta.model;
  }

  messages.push(...history);

  const lastMessage = messages[messages.length - 1];

  // Display the last message in the conversation
  const lastMessageFormatted = await formatMarkdown(lastMessage.content);
  console.log(ASSISTANT_PROMPT + lastMessageFormatted + "\n");
}

setTerminalTitle(CONVERSATION_BASENAME);

// Delete a previous conversation?
if (argv.delete) {
  const conversationBasename = await chooseConversation();

  if (!conversationBasename) {
    process.exit(1);
  }

  await $`rm ${ROOT_DIR}/${conversationBasename}.md`;

  console.log(META_FORMAT(`Deleted conversation "${conversationBasename}"`));

  process.exit(0);
}

// List sessions
if (argv.list) {
  const conversationBasenames = await getConversationBasenames();

  console.log("Conversations:");

  console.log();
  for (const conversationBasename of conversationBasenames) {
    console.log("  " + conversationBasename);
  }
  console.log();

  process.exit(0);
}

// Append the message and journal the conversation
const appendMessage = (message: ChatMessage) => {
  messages.push({ id: uuid4(), ...message });
  fs.writeFile(
    path.join(ROOT_DIR, `${CONVERSATION_BASENAME}.md`),
    stringifyChat(messages, { model }),
    (err) => {
      if (err) {
        console.error(err);
      }
    }
  );
};

// Stream the response to the console
async function streamResponse(userInput: string) {
  appendMessage({ role: "user", content: userInput });

  const stream = await openai.chat.completions.create({
    model,
    messages,
    stream: true,
  });

  // Show a spinner while streaming the response
  let buffer = "";
  await spinner(async () => {
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content ?? "";
      buffer += content;
    }
  });

  process.stdout.write(`\n${ASSISTANT_PROMPT}`);
  process.stdout.write(await formatMarkdown(buffer));

  process.stdout.write("\n\n" + USER_PROMPT);

  appendMessage({
    role: "assistant",
    content: buffer,
  });
}

// Welcome message
const action = messages.length ? "resumed" : "started";
console.log(
  META_FORMAT(
    `Chat with ${model} ${action}. Type '${EXIT_COMMAND}' to end the conversation. An empty line sends the current message buffer.\n`
  )
);

let inputBuffer = "";

// Main chat loop
while (true) {
  const input = await question(
    inputBuffer.length === 0 ? USER_PROMPT : USER_PROMPT_2
  );

  if (input.toLowerCase() === ".exit") {
    console.log(META_FORMAT(`Did you mean ${EXIT_COMMAND}?`));
    continue;
  }

  if (input.toLowerCase() === NEW_COMMAND) {
    console.clear();
    messages.length = 0;
    CONVERSATION_BASENAME = uuid4();
    setTerminalTitle(CONVERSATION_BASENAME);
    console.log(META_FORMAT(`Started a new conversation with ${model}.`));
    continue;
  }

  if (input.toLowerCase() === STATUS_COMMAND) {
    console.log(META_FORMAT(`Conversation: ${CONVERSATION_BASENAME}`));
    console.log(META_FORMAT(`Model:        ${model}`));
    console.log(META_FORMAT(`Messages:     ${messages.length}`));
    continue;
  }

  if (input.toLowerCase() === EXIT_COMMAND) {
    console.clear();
    process.exit(0);
  }

  if (input.startsWith(COPY_COMMAND)) {
    await $`echo ${messages[messages.length - 1].content} | pbcopy`;
    console.log(META_FORMAT(`Copied last message to clipboard.`));

    continue;
  }

  if (input.startsWith(RENAME_COMMAND)) {
    const newName = input.slice(RENAME_COMMAND.length).trim();
    const oldPath = path.join(ROOT_DIR, `${CONVERSATION_BASENAME}.md`);
    const newPath = path.join(ROOT_DIR, `${newName}.md`);

    await fs.rename(oldPath, newPath);

    console.log(META_FORMAT(`Renamed conversation to "${newName}"`));

    CONVERSATION_BASENAME = newName;
    setTerminalTitle(CONVERSATION_BASENAME);

    continue;
  }

  if (input.startsWith(DELETE_COMMAND)) {
    console.clear();

    // Clean up the conversation file
    await $`rm ${ROOT_DIR}/${CONVERSATION_BASENAME}.md`;
    console.log(META_FORMAT(`Deleted conversation "${CONVERSATION_BASENAME}"`));

    // Flush the messages
    messages.length = 0;

    // Start a new conversation
    CONVERSATION_BASENAME = uuid4();
    setTerminalTitle(CONVERSATION_BASENAME);
    console.log(META_FORMAT(`Started a new conversation with ${model}.`));

    continue;
  }

  // Non-empty lines are appended to the current message
  if (input.length !== 0) {
    inputBuffer += input;
    setStatusLine("Press ENTER again to send the message.");
    continue;
  }

  await streamResponse(inputBuffer);

  inputBuffer = "";
  setStatusLine("");
}
